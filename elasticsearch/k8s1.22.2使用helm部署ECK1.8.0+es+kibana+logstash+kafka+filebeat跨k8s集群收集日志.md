# k8s1.22.2使用helm部署ECK1.8.0+es+kibana+logstash+kafka+filebeat跨k8s集群收集日志

## 下载镜像列表到私有仓库

```
docker.elastic.co/eck/eck-operator:1.5.0
docker.elastic.co/elasticsearch/elasticsearch:7.15.1
docker.elastic.co/kibana/kibana:7.15.1
docker.elastic.co/beats/filebeat:7.15.1
docker.elastic.co/logstash/logstash:7.15.1

```

## 添加 helm repo

```
helm repo add elastic https://helm.elastic.co
helm repo update
```

## 下载 chart

```
# crds chart
helm pull elastic/eck-operator-crds
# eck-operator chart
helm pull elastic/eck-operator
```

## 安装 crds (由于crd是全局资源，不希望 helm 卸载 es eck 时同时卸载 crds ,所以独立安装)

```
helm upgrade --install elastic-operator-crds  eck-operator-crds-1.8.0.tgz -n elastic-system --create-namespace
```

## 安装 eck-operator

参考：https://github.com/elastic/cloud-on-k8s/blob/1.3/deploy/eck-operator/values.yaml

```
helm install elastic-operator eck-operator-1.8.0.tgz -n elastic-system --create-namespace \
--set=installCRDs=false \
--set=webhook.enabled=true \
--set=image.repository=registry.hisun.netwarps.com/eck/eck-operator \
--set=config.containerRegistry=registry.hisun.netwarps.com
```

## 安装 elasticsearch

创建 bfs-elasticsearch.yaml

```
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: bfs
  namespace: elastic-system
spec:
  version: 7.15.1
  http:
    tls:
      selfSignedCertificate:
        disabled: true
  nodeSets:
  - name: master
    count: 3
    config:
      node.roles: ["master", "data", "ingest", "ml", "transform"]
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data # pvc 名称不支持修改
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
        storageClassName: local-path
    podTemplate:
      spec:
        #nodeSelector:
        #  node-role.kubernetes.io/logging: 'true'
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
        containers:
        - name: elasticsearch
          securityContext:
            privileged: true
```

执行安装 es

```
kubectl apply -f bfs-elasticsearch.yaml
```

查看 es pod

```
kubectl get pod -n elastic-system -o wide
```

## 安装 kibana

创建 bfs-kibana.yaml

```
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: bfs
  namespace: elastic-system
spec:
  version: 7.15.1
  count: 1
  elasticsearchRef:
    name: bfs
```
执行安装 es

```
kubectl apply -f bfs-kibana.yaml 
```

查看 es pod

```
kubectl get pod -n elastic-system -o wide
```

查看 kibana svc 名称

```
kubectl get svc -n elastic-system
```

创建 kibana ingress yaml (根据环境修改 host)

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: bfs-kibana
  namespace: elastic-system
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS" # use backend https
spec:
  rules:
  - host: bfs-kibana.apps92250.hisun.k8s
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: bfs-kb-http # kibana svc name
            port:
              number: 5601
```

发布 kibana ingress

```
kubectl apply -f bfs-kibana-ingress.yaml
```

bfs-kibana.apps92250.hisun.k8s 解析到 ingress ip 或 lb ip

外部访问 kibana 

```
https://bfs-kibana.apps92250.hisun.k8s
```

kibana 默认登录账号为 elastic, 查看密码

```
kubectl get secret bfs-es-elastic-user -o=jsonpath='{.data.elastic}' -n elastic-system| base64 --decode; echo
```

## 部署 kafka

参考：[helm线下部署kafka-opertor.md](../kafka-operator/helm线下部署kafka-opertor.md) 部署外部使用 kafka 

## 外部 k8s 集群部署eck 和 filebeat

openshift3.11部署 eck 参考：https://liujinye.gitbook.io/openshift-docs/logging/openshift3.11-bu-shu-eck1.6+es7.14.1


filebeat.yaml

```
apiVersion: beat.k8s.elastic.co/v1beta1
kind: Beat
metadata:
  name: bfs
  namespace: elastic-system
spec:
  type: filebeat
  version: 7.15.1
  config:
    logging.level: info
    filebeat.inputs:
    - type: log
      paths:
      - /aos/pn-api/logs/access_*.log
      fields:
        app: pn-api
        type: access
    - type: log
      paths:
      - /aos/tn-api/logs/access_*.log
      fields:
        app: tn-api
        type: access
    - type: log
      paths:
      - /aos/rn-api/logs/access_*.log
      fields:
        app: rn-api
        type: access
    - type: log
      paths:
      - /data/bfs-gateway/runtime/logs/access.*.log
      fields:
        app: gw
        type: access
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /aos/pn-api/logs/pn_*.log
      fields:
        app: pn-api
        type: business
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /aos/tn-api/logs/tn_*.log
      fields:
        app: tn-api
        type: business
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /aos/rn-api/logs/rn_*.log
      fields:
        app: rn-api
        type: business
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /data/bfs-gateway/runtime/logs/gw.*.log
      fields:
        app: gw
        type: business
    - type: log
      paths:
      - /data/pld-nft/logs/access_*.log
      fields:
        app: pld-nft
        type: access
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /data/pld-nft/logs/nft_*.log
      fields:
        app: pld-nft
        type: business
    - type: log
      paths:
      - /data/netdisk/logs/access_*.log
      fields:
        app: networkdisk
        type: access
    - type: log
      multiline.type: pattern
      multiline.pattern: '^\['
      multiline.negate: true
      multiline.match: after
      paths:
      - /data/netdisk/logs/networkdisk_*.log
      fields:
        app: networkdisk
        type: business
    output.kafka:
      hosts: ["172.16.152.20:9094","172.16.142.252:9094","172.16.233.132:9094"]
      topic: '%{[fields.app]}-%{[fields.type]}'
      partition.round_robin:
        reachable_only: false
      required_acks: 1
      compression: gzip
      max_message_bytes: 1000000
  daemonSet:
    podTemplate:
      spec:
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        securityContext:
          runAsUser: 0
        containers:
        - name: filebeat
          securityContext:
            runAsUser: 0
            # If using Red Hat OpenShift uncomment this:
            privileged: true
          volumeMounts:
          - name: aos
            mountPath: /aos
            readOnly: true
          - name: data
            mountPath: /data
            readOnly: true
          - mountPath: /etc/localtime
            name: localtime
            readOnly: true
        volumes:
        - name: aos
          hostPath:
            path: /aos
        - name: data
          hostPath:
            path: /data
        - name: localtime
          hostPath:
            path: /etc/localtime
```

部署 filebeat

```
kubectl apply -f filebeat.yaml
```

## 当前集群部署 logstash 

bfs-access-logstash.yaml

```
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: bfs-access-logstash-configmap
  namespace: elastic-system
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    log.level: info
  logstash.conf: |
    # all input will come from filebeat, no local logs
    input {
      kafka {
        bootstrap_servers => "kafka-0.kafka.svc:29092,kafka-1.kafka.svc:29092,kafka-2.kafka.svc:29092"
        group_id => "bfs"
        client_id => "ls-bfs-access"
        consumer_threads => 2
        topics_pattern => ".*-access"
        codec => json { charset => "UTF-8" }
      }
    }
    filter {
        grok {
          match => {
             "message" => "^\[(?<app_name>.*)\] \[%{HOSTNAME:hostname}\] %{IPV4:ip} - \[(?<logtime>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND}))\] (?<method>[^ ]*) (?<uri>[^ ]*) (HTTP/%{NUMBER:http_version})? %{NUMBER:http_code} %{NUMBER:response_time} %{NUMBER:body_size} (?<x_request_id>[^ ]*) \"(?<other>.*)\""
          }
        }
      mutate {
        convert => { "http_code" => "integer" }
        convert => { "response_time" => "integer" }
        convert => { "body_size" => "integer" }
        convert => { "http_version" => "float" }
      }
      date{
        match => ["logtime", "yyyy-MM-dd HH:mm:ss"]
        target => "logtime"
        timezone => "+08:00"
        locale => "cn"
      }
    }
    output {
      elasticsearch {
        index => "bfs-apps"
        action => "create"
        hosts => [ "http://bfs-es-master.elastic-system.svc:9200" ]
        user => "${ELASTICSEARCH_USER}"
        password => "${ELASTICSEARCH_PASSWORD}"
        #cacert => '/etc/logstash/certificates/ca.crt'
      }
    }
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: bfs-access-logstash-data
  namespace: elastic-system
spec:
  storageClassName: local-path
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: bfs-access-logstash
  namespace: elastic-system
  labels:
    app: bfs-access-logstash
spec:
  replicas: 1
  selector:
    matchLabels:
      app: bfs-access-logstash
  template:
    metadata:
      labels:
        app: bfs-access-logstash
    spec:
      containers:
      - image: registry.hisun.netwarps.com/logstash/logstash:7.15.1
        name: bfs-access-logstash
        ports:
        - containerPort: 25826
        - containerPort: 5044
        env:
        - name: ES_HOSTS
          value: "http://bfs-es-master.elastic-system.svc:9200"
        - name: ELASTICSEARCH_USER
          value: "elastic"
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: bfs-es-elastic-user
              key: elastic
        resources: {}
        volumeMounts:
        - name: config-volume
          mountPath: /usr/share/logstash/config
        - name: logstash-pipeline-volume
          mountPath: /usr/share/logstash/pipeline
        - name: data
          mountPath: "/usr/share/logstash/data/"
          subPath: "data"
        - mountPath: /etc/localtime
          name: localtime
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: bfs-access-logstash-configmap
          items:
            - key: logstash.yml
              path: logstash.yml
      - name: logstash-pipeline-volume
        configMap:
          name: bfs-access-logstash-configmap
          items:
            - key: logstash.conf
              path: logstash.conf
      - name: data
        persistentVolumeClaim:
          claimName: bfs-access-logstash-data
      - name: localtime
        hostPath:
          path: /etc/localtime
```

```
kubectl apply -f bfs-access-logstash.yaml
```

bfs-business-logstash.yaml

```
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: bfs-business-logstash-configmap
  namespace: elastic-system
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    log.level: info
  logstash.conf: |
    # all input will come from filebeat, no local logs
    input {
      kafka {
        bootstrap_servers => "kafka-0.kafka.svc:29092,kafka-1.kafka.svc:29092,kafka-2.kafka.svc:29092"
        group_id => "bfs"
        client_id => "ls-bfs-business"
        consumer_threads => 2
        topics_pattern => ".*-business"
        codec => json { charset => "UTF-8" }
      }
    }
    filter {
        grok {
          match => {
             "message" => "^\[(?<level>.*)\] (?<logtime>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}:?%{SECOND}) (?<message>.*)"
          }
        }
      date{
        match => ["logtime", "yyyy-MM-dd HH:mm:ss"]
        target => "logtime"
        timezone => "+08:00"
        locale => "cn"
      }
    }
    output {
      elasticsearch {
        index => "bfs-apps"
        action => "create"
        hosts => [ "http://bfs-es-master.elastic-system.svc:9200" ]
        user => "${ELASTICSEARCH_USER}"
        password => "${ELASTICSEARCH_PASSWORD}"
        #cacert => '/etc/logstash/certificates/ca.crt'
      }
    }
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: bfs-business-logstash-data
  namespace: elastic-system
spec:
  storageClassName: local-path
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: bfs-business-logstash
  namespace: elastic-system
  labels:
    app: bfs-business-logstash
spec:
  replicas: 1
  selector:
    matchLabels:
      app: bfs-business-logstash
  template:
    metadata:
      labels:
        app: bfs-business-logstash
    spec:
      containers:
      - image: registry.hisun.netwarps.com/logstash/logstash:7.15.1
        name: bfs-business-logstash
        ports:
        - containerPort: 25826
        - containerPort: 5044
        env:
        - name: ES_HOSTS
          value: "http://bfs-es-http.elastic-system.svc:9200"
        - name: ELASTICSEARCH_USER
          value: "elastic"
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: bfs-es-elastic-user
              key: elastic
        resources: {}
        volumeMounts:
        - name: config-volume
          mountPath: /usr/share/logstash/config
        - name: logstash-pipeline-volume
          mountPath: /usr/share/logstash/pipeline
        - name: data
          mountPath: "/usr/share/logstash/data/"
          subPath: "data"
        - mountPath: /etc/localtime
          name: localtime
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: bfs-business-logstash-configmap
          items:
            - key: logstash.yml
              path: logstash.yml
      - name: logstash-pipeline-volume
        configMap:
          name: bfs-business-logstash-configmap
          items:
            - key: logstash.conf
              path: logstash.conf
      - name: data
        persistentVolumeClaim:
          claimName: bfs-business-logstash-data
      - name: localtime
        hostPath:
          path: /etc/localtime
```

```
kubectl apply -f bfs-business-logstash.yaml
```

## kibana 创建索引 

访问 https://bfs-kibana.apps92250.hisun.k8s/

创建 bfs-apps 索引 

## 参考

https://github.com/elastic/cloud-on-k8s

https://github.com/ss75710541/operator-env/blob/main/elasticsearch/helm%E7%BA%BF%E4%B8%8B%E9%83%A8%E7%BD%B2ECK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86es%E7%A6%81%E7%94%A8tls%2B%E6%94%B6%E9%9B%86k8s%E6%97%A5%E5%BF%97.md

https://github.com/ss75710541/operator-env/blob/main/elasticsearch/helm%E5%8D%87%E7%BA%A7ECK.md

https://github.com/ss75710541/openshift-docs/blob/master/logging/openshift3.11%E9%83%A8%E7%BD%B2eck1.6%2Bes7.14.1.md

